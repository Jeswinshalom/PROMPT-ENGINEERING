19TD608- PROMPT ENGINEERING                                                                    
JESWIIN SHALOM S  
212223060106 
ECE, 2nd year 
EXPERIMENT-1 
Fundamentals of Generative AI and 
Large Language Models 
1. Introduction 
Generative Artificial Intelligence (Generative AI) refers to a subset 
of AI that focuses on generating new content—text, images, music, 
code, and more—based on patterns learned from training data. 
Large Language Models (LLMs) are a key application of 
generative AI, particularly focused on understanding and 
generating human language. 
2. What is Generative AI? 
Generative AI uses machine learning models to create new data 
similar to the training data it was exposed to. It is capable of: - Generating human-like text - Creating images, audio, or videos - Writing code and composing music 
 
Key Techniques in Generative AI: - Generative Adversarial Networks (GANs) - Variational Autoencoders (VAEs) - Transformers (used in LLMs) 
 
3. What are Large Language Models (LLMs)? 
LLMs are AI models trained on vast amounts of textual data to 
perform various tasks involving natural language. They are based 
on the transformer architecture and are trained using unsupervised 
or semi-supervised learning. 
Examples: - GPT (Generative Pre-trained Transformer) by OpenAI - BERT (Bidirectional Encoder Representations from 
Transformers) by Google - LLaMA (Large Language Model Meta AI) by Meta 
4. Architecture of LLMs 
Transformer Architecture: 
Introduced by Vaswani et al. in 2017, the transformer model 
replaced traditional RNNs and CNNs in NLP tasks due to its 
efficiency and scalability. 
Key components: - Self-Attention Mechanism - Encoder-Decoder Structure (in some models) - Positional Encoding 
5. Training of LLMs 
Phases: 
1. Pre-training: The model learns general language representations 
from massive datasets (e.g., books, websites). 
2. Fine-tuning: The model is trained on task-specific data for 
improved performance. 
Training Data: - Internet text (e.g., Wikipedia, news articles) - Books, forums, coding platforms, etc. 
6. Applications of Generative AI and LLMs - Text generation (e.g., ChatGPT, content writing) - Machine translation - Summarization - Sentiment analysis - Question answering - Code generation (e.g., GitHub Copilot) - Chatbots and Virtual Assistants 
7. Ethical Considerations and Challenges 
Concerns: - Bias - Misinformation - Plagiarism - Job displacement 
Solutions: - Bias mitigation techniques - Fact-checking integrations - Transparent AI development - Human oversight in deployment 
8. Future Directions - Smaller, efficient models - Multimodal models - Open-source LLMs - Continual learning 
9. Conclusion 
Generative AI and Large Language Models represent a major leap 
in artificial intelligence capabilities. With transformative potential 
across industries, they also require careful consideration of ethical, 
technical, and societal impacts. As the field evolves, striking a 
balance between innovation and responsibility will be key to 
harnessing their power for good.
